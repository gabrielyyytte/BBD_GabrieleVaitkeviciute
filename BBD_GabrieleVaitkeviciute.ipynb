{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxZ3pOzHBf0O"
      },
      "source": [
        "-------PREPARING ENVIRONMENT--------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nnd-sXcNc3Uf"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVruJ9ixc3qU"
      },
      "outputs": [],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pBTUGJ_Bt3z"
      },
      "source": [
        "--------DATA PREPROCESSING--------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJQC3IM96zRt"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wt2PHbyYYrf4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the CSV file using numpy.genfromtxt()\n",
        "data = np.genfromtxt('/content/gdrive/MyDrive/Bakalauras/train_data_RR_1_05_31_newest.csv', delimiter=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJY-t4GrvPs1"
      },
      "outputs": [],
      "source": [
        "data = np.delete(data, 0, axis=0)\n",
        "data = np.delete(data, 0, axis=1)\n",
        "\n",
        "train_labels = data[:, 1]\n",
        "train_data = np.delete(data, 1, axis=1)\n",
        "\n",
        "print(\"Initial data\")\n",
        "print(\"Class 0:\")\n",
        "print(np.count_nonzero(train_labels == 0))\n",
        "print(\"Class 1:\")\n",
        "print(np.count_nonzero(train_labels == 1))\n",
        "print(\"Class 2:\")\n",
        "print(np.count_nonzero(train_labels == 2))\n",
        "print(\"Initial data length:\")\n",
        "print(len(train_labels))\n",
        "\n",
        "faulty_indices = np.where(train_labels == 3)\n",
        "faulty_indices = faulty_indices[0].tolist()\n",
        "\n",
        "train_labels = np.delete(train_labels,[faulty_indices],axis=0)\n",
        "train_data = np.delete(train_data,[faulty_indices],axis=0)\n",
        "\n",
        "print(\"Initial data length (no noise):\")\n",
        "print(len(train_labels))\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "\n",
        "# SKIP WHEN TRAINING RANDOM FOREST\n",
        "train_data, validation_data, train_labels, validation_labels = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Training data\")\n",
        "print(\"Class 0:\")\n",
        "print(np.count_nonzero(train_labels == 0))\n",
        "print(\"Class 1:\")\n",
        "print(np.count_nonzero(train_labels == 1))\n",
        "print(\"Class 2:\")\n",
        "print(np.count_nonzero(train_labels == 2))\n",
        "print(\"Training data length:\")\n",
        "print(len(train_labels))\n",
        "\n",
        "print(\"Validation data\")\n",
        "print(\"Class 0:\")\n",
        "print(np.count_nonzero(validation_labels == 0))\n",
        "print(\"Class 1:\")\n",
        "print(np.count_nonzero(validation_labels == 1))\n",
        "print(\"Class 2:\")\n",
        "print(np.count_nonzero(validation_labels == 2))\n",
        "print(\"Validation data length:\")\n",
        "print(len(validation_labels))\n",
        "\n",
        "# END OF SKIPPABLE CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M0eVxayEZFm"
      },
      "source": [
        "----------DATA BALANCING----------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdYKEPWUEYWC"
      },
      "outputs": [],
      "source": [
        "# SMOTE\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "smote_train_data, smote_labels = smote.fit_resample(train_data, train_labels)\n",
        "\n",
        "print(\"SMOTE balanced data\")\n",
        "print(\"Class 0:\")\n",
        "print(np.count_nonzero(smote_labels == 0))\n",
        "print(\"Class 1:\")\n",
        "print(np.count_nonzero(smote_labels == 1))\n",
        "print(\"Class 2:\")\n",
        "print(np.count_nonzero(smote_labels == 2))\n",
        "print(\"SMOTE data length:\")\n",
        "print(len(smote_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fC6FdThwE1A1"
      },
      "outputs": [],
      "source": [
        "# RANDOM OVERSAMPLING\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "oversample = RandomOverSampler(random_state=42)\n",
        "random_oversampling_train_data, random_oversampling_labels = oversample.fit_resample(train_data, train_labels)\n",
        "\n",
        "print(\"RANDOM OVERSAMPLING balanced data\")\n",
        "print(\"Class 0:\")\n",
        "print(np.count_nonzero(random_oversampling_labels == 0))\n",
        "print(\"Class 1:\")\n",
        "print(np.count_nonzero(random_oversampling_labels == 1))\n",
        "print(\"Class 2:\")\n",
        "print(np.count_nonzero(random_oversampling_labels == 2))\n",
        "print(\"RANDOM OVERSAMPLING data length:\")\n",
        "print(len(random_oversampling_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7Fv8S9RSGiY"
      },
      "outputs": [],
      "source": [
        "# RANDOM UNDERSAMPLING\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "undersample = RandomUnderSampler(random_state=42)\n",
        "random_undersampling_train_data, random_undersampling_labels = undersample.fit_resample(train_data, train_labels)\n",
        "\n",
        "\n",
        "print(\"RANDOM UNDERSAMPLING balanced data\")\n",
        "print(\"Class 0:\")\n",
        "print(np.count_nonzero(random_undersampling_labels == 0))\n",
        "print(\"Class 1:\")\n",
        "print(np.count_nonzero(random_undersampling_labels == 1))\n",
        "print(\"Class 2:\")\n",
        "print(np.count_nonzero(random_undersampling_labels == 2))\n",
        "print(\"RANDOM UNDERSAMPLING data length:\")\n",
        "print(len(random_undersampling_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c91cQz03Rkal"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Perform ADASYN to balance the dataset\n",
        "adasyn = ADASYN(random_state=42)\n",
        "adasyn_train_data, adasyn_labels = adasyn.fit_resample(train_data, train_labels)\n",
        "\n",
        "print(\"ADASYN balanced data\")\n",
        "print(\"Class 0:\")\n",
        "print(np.count_nonzero(adasyn_labels == 0))\n",
        "print(\"Class 1:\")\n",
        "print(np.count_nonzero(adasyn_labels == 1))\n",
        "print(\"Class 2:\")\n",
        "print(np.count_nonzero(adasyn_labels == 2))\n",
        "print(\"ADASYN data length:\")\n",
        "print(len(adasyn_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8baSdbxwx87W"
      },
      "outputs": [],
      "source": [
        "from imblearn.combine import SMOTEENN\n",
        "smote_enn = SMOTEENN(random_state=42)\n",
        "balanced_train_data, balanced_labels = smote_enn.fit_resample(train_data, train_labels)\n",
        "\n",
        "print(\"Mixed balanced data\")\n",
        "print(\"Class 0:\")\n",
        "print(np.count_nonzero(balanced_labels == 0))\n",
        "print(\"Class 1:\")\n",
        "print(np.count_nonzero(balanced_labels == 1))\n",
        "print(\"Class 2:\")\n",
        "print(np.count_nonzero(balanced_labels == 2))\n",
        "print(\"Mixed data length:\")\n",
        "print(len(balanced_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIcuZeLTET7i"
      },
      "source": [
        "--------TRAINING---------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCIANCphFOQd"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# Import provided model\n",
        "model = keras.models.load_model('/content/gdrive/MyDrive/Bakalauras/best_model_final.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHr0RNuA4wmj"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def train(train_data, train_labels, validation_data, validation_labels):\n",
        "    # Copying layers from the provided model\n",
        "    new_model = keras.models.clone_model(model)\n",
        "\n",
        "    early_stopping_monitor = keras.callbacks.EarlyStopping(\n",
        "      monitor='val_loss',\n",
        "      min_delta=0,\n",
        "      patience=5,\n",
        "      verbose=0,\n",
        "      mode='auto',\n",
        "      baseline=None,\n",
        "      restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    # Compiling - adding optimizer, loss function, metrics\n",
        "    new_model.compile(\n",
        "        optimizer=keras.optimizers.Adam(),\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=[keras.metrics.SparseCategoricalAccuracy(), \"MAE\"],\n",
        "    )\n",
        "\n",
        "    # Training\n",
        "    history = new_model.fit(\n",
        "        train_data,\n",
        "        train_labels,\n",
        "        epochs=10,\n",
        "        validation_data=(validation_data, validation_labels),\n",
        "        callbacks=[early_stopping_monitor]\n",
        "    )\n",
        "\n",
        "\n",
        "    # Plotting model accuracy\n",
        "    plt.plot(history.history['sparse_categorical_accuracy'])\n",
        "    plt.plot(history.history['val_sparse_categorical_accuracy'])\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "    # Plotting model loss\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "    return new_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCuV726MDqar"
      },
      "outputs": [],
      "source": [
        "# After training the model, save with proper naming - For example, for SMOTE balancing, name the model - \"SMOTE_model.h5\"\n",
        "print(\"Training primary model\")\n",
        "primary_model = train(train_data, train_labels, validation_data, validation_labels)\n",
        "print(\"Training SMOTE model\")\n",
        "smote_model = train(smote_train_data, smote_labels, validation_data, validation_labels)\n",
        "print(\"Training random oversampling model\")\n",
        "random_oversampling_model = train(random_oversampling_train_data, random_oversampling_labels, validation_data, validation_labels)\n",
        "print(\"Training random undersampling model\")\n",
        "random_undersampling_model = train(random_undersampling_train_data, random_undersampling_labels, validation_data, validation_labels)\n",
        "print(\"Training ADASYN model\")\n",
        "adasyn_model = train(adasyn_train_data, adasyn_labels, validation_data, validation_labels)\n",
        "print(\"Training balanced model\")\n",
        "balanced_model = train(balanced_train_data, balanced_labels, validation_data, validation_labels)\n",
        "\n",
        "\n",
        "primary_model.save('/content/gdrive/MyDrive/Bakalauras/primary_model.h5')\n",
        "smote_model.save('/content/gdrive/MyDrive/Bakalauras/smote_model.h5')\n",
        "random_oversampling_model.save('/content/gdrive/MyDrive/Bakalauras/random_oversampling_model.h5')\n",
        "random_undersampling_model.save('/content/gdrive/MyDrive/Bakalauras/random_undersampling_model.h5')\n",
        "adasyn_model.save('/content/gdrive/MyDrive/Bakalauras/adasyn_model.h5')\n",
        "balanced_model.save('/content/gdrive/MyDrive/Bakalauras/balanced_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FC2peEKWDFSp"
      },
      "source": [
        "-----------TESTING-------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcLqDOoQC1QX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "# PREPARING TEST DATA\n",
        "test_data = np.genfromtxt('/content/gdrive/MyDrive/Bakalauras/test_data_RR_1_05_31_newest.csv', delimiter=',')\n",
        "\n",
        "test_data = np.delete(test_data, 0, axis=0)\n",
        "test_data = np.delete(test_data, 0, axis=1)\n",
        "\n",
        "test_labels = test_data[:, 1]\n",
        "\n",
        "test_data = np.delete(test_data, 1, axis=1)\n",
        "\n",
        "print(\"Testing data\")\n",
        "print(\"Class 0:\")\n",
        "print(np.count_nonzero(test_labels == 0))\n",
        "print(\"Class 1:\")\n",
        "print(np.count_nonzero(test_labels == 1))\n",
        "print(\"Class 2:\")\n",
        "print(np.count_nonzero(test_labels == 2))\n",
        "print(\"Testing data length:\")\n",
        "print(len(test_labels))\n",
        "\n",
        "faulty_indices = np.where(test_labels == 3)\n",
        "faulty_indices = faulty_indices[0].tolist()\n",
        "\n",
        "test_labels = np.delete(test_labels,[faulty_indices],axis=0)\n",
        "test_data = np.delete(test_data,[faulty_indices],axis=0)\n",
        "\n",
        "print(\"Testing data length (no noise):\")\n",
        "print(len(test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8w2YTDYimlc"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def test(model):\n",
        "    results = model.evaluate(test_data, test_labels)\n",
        "    print(\"test loss, test acc:\", results)\n",
        "  \n",
        "    y_pred = model.predict(test_data)\n",
        "  \n",
        "    predictions = []\n",
        "    for prediction in y_pred:\n",
        "        predictions.append(np.argmax(prediction))\n",
        "    \n",
        "    print(confusion_matrix(test_labels, predictions))\n",
        "    print(classification_report(test_labels, predictions))\n",
        "\n",
        "    report = classification_report(test_labels, predictions, output_dict=True)\n",
        "    report_df = pd.DataFrame(report).transpose()\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    sns.heatmap(report_df.iloc[:-3, :-1], annot=True, cmap=\"Blues\", ax=ax, cbar=False)\n",
        "    ax.set_ylabel('Labels')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2phidF87LUU"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# Load model for testing. \n",
        "primary_model = keras.models.load_model('/content/gdrive/MyDrive/Bakalauras/primary_model.h5')\n",
        "smote_model = keras.models.load_model('/content/gdrive/MyDrive/Bakalauras/smote_model.h5')\n",
        "random_oversampling_model = keras.models.load_model('/content/gdrive/MyDrive/Bakalauras/random_oversampling_model.h5')\n",
        "random_undersampling_model = keras.models.load_model('/content/gdrive/MyDrive/Bakalauras/random_undersampling_model.h5')\n",
        "adasyn_model = keras.models.load_model('/content/gdrive/MyDrive/Bakalauras/adasyn_model.h5')\n",
        "balanced_model = keras.models.load_model('/content/gdrive/MyDrive/Bakalauras/balanced_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPjKhVR8KBhu"
      },
      "outputs": [],
      "source": [
        "print(\"Testing primary model\")\n",
        "test(primary_model)\n",
        "print(\"----------\")\n",
        "print(\"Testing SMOTE\")\n",
        "test(smote_model)\n",
        "print(\"----------\")\n",
        "print(\"Testing random oversampling\")\n",
        "test(random_oversampling_model)\n",
        "print(\"----------\")\n",
        "print(\"Testing random undersampling\")\n",
        "test(random_undersampling_model)\n",
        "print(\"----------\")\n",
        "print(\"Testing adasyn undersampling\")\n",
        "test(adasyn_model)\n",
        "print(\"----------\")\n",
        "print(\"Testing balanced model\")\n",
        "test(balanced_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fio0noM9zcAu"
      },
      "source": [
        "-------------------------RANDOM FOREST--------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEWJNe7E0IRz"
      },
      "outputs": [],
      "source": [
        "# Modelling\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay, classification_report\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split, cross_val_score, cross_val_predict\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Tree Visualisation\n",
        "from sklearn.tree import export_graphviz\n",
        "from IPython.display import Image\n",
        "import graphviz\n",
        "\n",
        "def find_random_forest_hyperparams(train_data, train_labels):\n",
        "    param_grid = {\n",
        "    'n_estimators': [75, 88, 100],\n",
        "    'max_features': ['sqrt'],\n",
        "    'max_depth': [16, 18, None],\n",
        "    'max_leaf_nodes': [15, 18, None],\n",
        "    }\n",
        "\n",
        "    # Create a random forest classifier\n",
        "    rf = RandomForestClassifier()\n",
        "\n",
        "    # Use random search to find the best hyperparameters\n",
        "    rand_search = RandomizedSearchCV(rf, param_grid)\n",
        "\n",
        "    # Fit the random search object to the data\n",
        "    rand_search.fit(train_data, train_labels)\n",
        "\n",
        "    # Create a variable for the best model\n",
        "    best_rf = rand_search.best_estimator_\n",
        "\n",
        "    # Print the best hyperparameters\n",
        "    print('Best hyperparameters:',  rand_search.best_params_)\n",
        "\n",
        "    return best_rf\n",
        "\n",
        "\n",
        "def train_random_forest(train_data, train_labels):\n",
        "    # Create a random forest classifier\n",
        "    \n",
        "    # Best hyperparameters: {'n_estimators': 75, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': 18}\n",
        "\n",
        "    rf = RandomForestClassifier(n_estimators=75, max_leaf_nodes=None, max_features=\"sqrt\", max_depth=18)\n",
        "\n",
        "    # Fit the random search classifier to the data\n",
        "    rf.fit(train_data, train_labels)\n",
        "    predicted_labels = cross_val_predict(rf, train_data, train_labels, cv=10)\n",
        "\n",
        "    accuracy = accuracy_score(train_labels, predicted_labels)\n",
        "    confusion_mat = confusion_matrix(train_labels, predicted_labels)\n",
        "    classif_report = classification_report(train_labels, predicted_labels)\n",
        "\n",
        "    print(\"Classification report:\")\n",
        "    print(classif_report)\n",
        "    print(\"Accuracy: %0.2f\" % accuracy)\n",
        "    print(\"Confusion matrix:\")\n",
        "    print(confusion_mat)\n",
        "\n",
        "    return rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b26RXIAR00t-"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "#After training the model, save with proper naming - For example, for SMOTE balancing, name the model - \"SMOTE_model.h5\"\n",
        "best_rf = find_random_forest_hyperparams(train_data, train_labels)\n",
        "print(\"Training primary random forest classifier\")\n",
        "best_rf_primary = train_random_forest(train_data, train_labels)\n",
        "joblib.dump(best_rf_primary, \"/content/gdrive/MyDrive/Bakalauras/best_rf_primary.joblib\")\n",
        "print(\"-----------------------\")\n",
        "print(\"Training SMOTE random forest classifier\")\n",
        "best_rf_smote = train_random_forest(smote_train_data, smote_labels)\n",
        "joblib.dump(best_rf_smote, \"/content/gdrive/MyDrive/Bakalauras/best_rf_smote.joblib\")\n",
        "print(\"-----------------------\")\n",
        "print(\"Training random oversampling random forest classifier\")\n",
        "best_rf_rand_oversampling = train_random_forest(random_oversampling_train_data, random_oversampling_labels)\n",
        "joblib.dump(best_rf_rand_oversampling, \"/content/gdrive/MyDrive/Bakalauras/best_rf_rand_oversampling.joblib\")\n",
        "print(\"-----------------------\")\n",
        "print(\"Training random undersampling random forest classifier\")\n",
        "best_rf_rand_undersampling = train_random_forest(random_undersampling_train_data, random_undersampling_labels)\n",
        "joblib.dump(best_rf_rand_undersampling, \"/content/gdrive/MyDrive/Bakalauras/best_rf_rand_undersampling.joblib\")\n",
        "print(\"Training adasyn random forest classifier\")\n",
        "best_rf_adasyn_undersampling = train_random_forest(adasyn_train_data, adasyn_labels)\n",
        "joblib.dump(best_rf_adasyn_undersampling, \"/content/gdrive/MyDrive/Bakalauras/best_rf_adasyn_undersampling.joblib\")\n",
        "print(\"Training balanced classifier\")\n",
        "best_rf_balanced = train_random_forest(balanced_train_data, balanced_labels)\n",
        "joblib.dump(best_rf_balanced, \"/content/gdrive/MyDrive/Bakalauras/best_rf_balanced.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idWiqp_jpkww"
      },
      "outputs": [],
      "source": [
        "# Modelling\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay, classification_report\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split, cross_val_score, cross_val_predict\n",
        "from scipy.stats import randint\n",
        "\n",
        "def test_random_forest(classifier):\n",
        "  y_pred = classifier.predict(test_data)\n",
        "\n",
        "  # Create the confusion matrix\n",
        "  cm = confusion_matrix(test_labels, y_pred)\n",
        "\n",
        "  ConfusionMatrixDisplay(confusion_matrix=cm).plot();\n",
        "  accuracy = accuracy_score(test_labels, y_pred)\n",
        "  confusion_mat = confusion_matrix(test_labels, y_pred)\n",
        "  classif_report = classification_report(test_labels, y_pred)\n",
        "  print(\"Classification report:\")\n",
        "  print(classif_report)\n",
        "  print(\"Accuracy: %0.2f\" % accuracy)\n",
        "  print(\"Confusion matrix:\")\n",
        "  print(confusion_mat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6uLfDKVqt6G"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "# Loading RF classifiers\n",
        "best_rf_primary = joblib.load(\"/content/gdrive/MyDrive/Bakalauras/best_rf_primary.joblib\")\n",
        "best_rf_smote = joblib.load(\"/content/gdrive/MyDrive/Bakalauras/best_rf_smote.joblib\")\n",
        "best_rf_rand_oversampling = joblib.load(\"/content/gdrive/MyDrive/Bakalauras/best_rf_rand_oversampling.joblib\")\n",
        "best_rf_rand_undersampling = joblib.load(\"/content/gdrive/MyDrive/Bakalauras/best_rf_rand_undersampling.joblib\")\n",
        "best_rf_adasyn_undersampling = joblib.load(\"/content/gdrive/MyDrive/Bakalauras/best_rf_adasyn_undersampling.joblib\")\n",
        "best_rf_balanced = joblib.load(\"/content/gdrive/MyDrive/Bakalauras/best_rf_balanced.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMChvIvo98kP"
      },
      "outputs": [],
      "source": [
        "# Testing RF classifiers\n",
        "print(\"Testing primary RF classifier\")\n",
        "test_random_forest(best_rf_primary)\n",
        "print(\"----------\")\n",
        "print(\"Testing SMOTE RF classifier\")\n",
        "test_random_forest(best_rf_smote)\n",
        "print(\"----------\")\n",
        "print(\"Testing random oversampling RF classifier\")\n",
        "test_random_forest(best_rf_rand_oversampling)\n",
        "print(\"----------\")\n",
        "print(\"Testing random undersampling RF classifier\")\n",
        "test_random_forest(best_rf_rand_undersampling)\n",
        "print(\"----------\")\n",
        "print(\"Testing adasyn undersampling RF classifier\")\n",
        "test_random_forest(best_rf_adasyn_undersampling)\n",
        "print(\"----------\")\n",
        "print(\"Testing balanced RF classifier\")\n",
        "test_random_forest(best_rf_balanced)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}